{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b56cb82a0c8c4d0ab80cc181068e567f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c546b98e98ca4c40bc42f566281fcb66",
              "IPY_MODEL_f79e80df9eb44ea580588530104c973d",
              "IPY_MODEL_5059677517634d9e96510e1aa3e5b4ed"
            ],
            "layout": "IPY_MODEL_eea5619602ac4bb5b68f6eadc22e707a"
          }
        },
        "c546b98e98ca4c40bc42f566281fcb66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_600cf47af5324c7f84d3bb4a0343a78d",
            "placeholder": "​",
            "style": "IPY_MODEL_577b6acfd4594c0e97f093b08f76ae8c",
            "value": "Map: 100%"
          }
        },
        "f79e80df9eb44ea580588530104c973d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abee0c269e51483e919a4f3d072544f6",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38e12ddb6d744172806bad386ddcb71f",
            "value": 500
          }
        },
        "5059677517634d9e96510e1aa3e5b4ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00ba81e1f8044b4e8b822bb10e9e4f16",
            "placeholder": "​",
            "style": "IPY_MODEL_af3bc746bee146619153d442337a9e9e",
            "value": " 500/500 [00:00&lt;00:00, 17906.78 examples/s]"
          }
        },
        "eea5619602ac4bb5b68f6eadc22e707a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "600cf47af5324c7f84d3bb4a0343a78d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "577b6acfd4594c0e97f093b08f76ae8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abee0c269e51483e919a4f3d072544f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38e12ddb6d744172806bad386ddcb71f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00ba81e1f8044b4e8b822bb10e9e4f16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af3bc746bee146619153d442337a9e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 环境介绍\n",
        "本示例运行在google colab L4，如果选择T4可能会遇到资源不足的情况。\n",
        "\n",
        "# 本示例概要\n",
        "本示例主要是带领大家如何使用Unsloth对已经将DeepSeek-R1蒸馏到小模型Llama8b的版本进行微调所构建医疗专家的模型，那我们接着来实作吧。"
      ],
      "metadata": {
        "id": "jp4iwJO1D7vF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 利用 Unsloth 微調 DeepSeek-R1-Distill-Llama-8B\n",
        "\n",
        "在此筆記本中，它將示範如何使用醫療資料集透過 Unsloth 微調 DeepSeek-R1-Distill-Llama-8B 實操。"
      ],
      "metadata": {
        "id": "ocKVFlsQ7AEb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 為什麼需要LLM微調？\n",
        "\n",
        "微調可以使模型在特定任務上有更好的表現，使其在實際應用中更有效、更靈活。像這次示例就是想構建醫療專家模型，希望回答的內容更加貼近目標答案。\n",
        "此流程對於根據特定任務或領域自訂現有模型至關重要。\n",
        "\n",
        "### 安裝unsloth\n",
        "unslotg 是開源大模型微調工具包"
      ],
      "metadata": {
        "id": "KjNVMqgs7md1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rPrLYn6G6Xzd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install unsloth\n",
        "# Also get the latest nightly Unsloth!\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n",
        "!pip install bitsandbytes unsloth_zoo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai-whisper\n",
        "!pip install -q ffmpeg"
      ],
      "metadata": {
        "id": "un_rf7498zOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 選擇一個基礎模型\n",
        "\n",
        "1. 選擇符合你用例的模型(例如視覺需求就選擇視覺表現好的模型作為基座，如果是針對編碼表現好的就選擇coder的模型作為基座)\n",
        "2. 評估您的儲存、運算能力和資料集（查看自己的硬體和手頭所擁有的數據集，來選擇一款合適的參數規格模型）\n",
        "3. 選擇模型和參數\n",
        "4. 在基礎模型和指導模型之間進行選擇"
      ],
      "metadata": {
        "id": "uym8RFUF8NXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "# from_pretrained for download model\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/DeepSeek-R1-Distill-Llama-8B\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ],
      "metadata": {
        "id": "VHYjGnAu8P_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 微調前的推理"
      ],
      "metadata": {
        "id": "bkpSnYPu8lf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
        "\n",
        "### Instruction:\n",
        "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning.\n",
        "Please answer the following medical question.\n",
        "\n",
        "### Question:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "<think>{}\"\"\""
      ],
      "metadata": {
        "id": "_i6PD6iM82U6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"一个患有急性阑尾炎的病人已经发病5天，腹痛稍有减轻但仍然发热，在体检时发现右下腹有压痛的包块，此时应如何处理？\"\n",
        "\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids=inputs.input_ids,\n",
        "    attention_mask=inputs.attention_mask,\n",
        "    max_new_tokens=1200,\n",
        "    use_cache=True,\n",
        ")\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "print(response[0].split(\"### Response:\")[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QAs3QIY86Ay",
        "outputId": "629fdb04-1f8e-4e8d-be61-0c1d5dbbb4af"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<think>\n",
            "好的，我现在需要帮助处理一个急性阑尾炎患者的情况。患者已经发病5天，腹痛有所减轻但仍然发热。在体检时，发现了右下腹有压痛的包块。作为医生，我需要仔细思考如何处理这个情况。\n",
            "\n",
            "首先，急性阑尾炎通常表现为右下腹疼痛、发热、发凉、腹部压痛等症状。患者已经有5天的病程，虽然腹痛有所缓解，但仍有发热，这可能意味着炎症尚未完全缓解，或者可能有其他并发症需要考虑。\n",
            "\n",
            "体检发现右下腹有压痛的包块，这可能有两种解释：一是阑尾炎的包块，尤其是右下腹的压痛，这与阑尾炎的典型表现一致；二是其他如腺体炎症或其他胰腺、肝脏的问题，但考虑到发热和腹痛，阑尾炎仍然是首选。\n",
            "\n",
            "接下来，我需要评估患者的症状和体征是否需要进一步的影像学检查。X光或超声检查可以帮助确认包块的性质，是否有扭转、积液或其他结构异常。例如，如果包块是扭转的阑尾，可能需要手术治疗；如果是积液，可能需要引流。\n",
            "\n",
            "如果包块是阑尾的扭转或阻塞，可能需要进行手术，特别是如果患者有明显的症状，如持续发热、恶心、呕吐等。手术可以帮助缓解症状，防止感染。\n",
            "\n",
            "另一方面，如果包块不是阑尾的，而是其他结构，比如胰腺炎症或肝脏问题，可能需要针对性治疗，比如抗生素、抗病毒药物或其他内科治疗。\n",
            "\n",
            "此外，患者的腹痛虽然有所缓解，但仍有发热，这可能提示炎症仍在活动，需要继续抗生素治疗以防止感染。同时，评估是否有其他症状，如发凉、腹泻等，以帮助诊断。\n",
            "\n",
            "在处理过程中，应该密切监测患者的症状，及时进行影像学检查，以明确包块的性质和后续治疗方案。同时，考虑患者的年龄、病史和其他可能的并发症，制定个性化的治疗计划。\n",
            "\n",
            "总结来说，处理这种情况的关键步骤是：1. 确认诊断，2. 影像学检查确认包块性质，3. 根据检查结果决定是否手术或其他治疗，4. 继续观察和管理患者的症状。\n",
            "\n",
            "现在，我需要将这些思考整理成一个连贯的步骤，确保每一步都清晰明确，能够指导实际的处理过程。\n",
            "</think>\n",
            "\n",
            "对于一个患有急性阑尾炎的患者，腹痛虽有缓解但仍发热，体检发现右下腹压痛包块，处理步骤如下：\n",
            "\n",
            "1. **确认诊断**：基于症状和体征，确认为急性阑尾炎，排除其他可能如腺体炎症。\n",
            "\n",
            "2. **影像学检查**：进行X光或超声，确定包块性质，如扭转、积液或其他异常。\n",
            "\n",
            "3. **评估并发症**：检查是否有扭转或阻塞，决定是否需要手术。\n",
            "\n",
            "4. **继续抗生素治疗**：根据检查结果调整药物，防止感染。\n",
            "\n",
            "5. **监测症状**：密切观察腹痛和发热情况，及时调整治疗。\n",
            "\n",
            "6. **考虑特殊情况**：如包块不是阑尾，需针对性治疗。\n",
            "\n",
            "通过以上步骤，确保患者得到及时、有效的处理，避免并发症。<｜end▁of▁sentence｜>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備資料集\n",
        "\n",
        "將使用醫療資料集 [https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT/](https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT/) 來訓練所選模型。"
      ],
      "metadata": {
        "id": "1MT5AzTx9EDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
        "\n",
        "### Instruction:\n",
        "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning.\n",
        "Please answer the following medical question.\n",
        "\n",
        "### Question:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "<think>\n",
        "{}\n",
        "</think>\n",
        "{}\"\"\""
      ],
      "metadata": {
        "id": "1mUABmg8-Ppg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 重要通知\n",
        "\n",
        "在每個訓練資料集條目末尾添加 EOS（序列結束）標記至關重要，否則您可能會遇到無限的生成。"
      ],
      "metadata": {
        "id": "Qgd9Gsxe-eQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n",
        "\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    inputs = examples[\"Question\"]\n",
        "    cots = examples[\"Complex_CoT\"]\n",
        "    outputs = examples[\"Response\"]\n",
        "    texts = []\n",
        "    for input, cot, output in zip(inputs, cots, outputs):\n",
        "        text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return {\n",
        "        \"text\": texts,\n",
        "    }"
      ],
      "metadata": {
        "id": "mDNxOBnn-PqR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", 'zh', split = \"train[0:500]\", trust_remote_code=True)\n",
        "print(dataset.column_names)"
      ],
      "metadata": {
        "id": "1v5ksSBa-it-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "為了讓「Ollama」和「llama.cpp」像自訂「ChatGPT」聊天機器人一樣運行，我們必須只有 2 列——「指令」和「輸出」列。我們需要將資料集轉換為適當的結構。"
      ],
      "metadata": {
        "id": "fKgNmIou-ppO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(formatting_prompts_func, batched = True)\n",
        "dataset[\"text\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193,
          "referenced_widgets": [
            "b56cb82a0c8c4d0ab80cc181068e567f",
            "c546b98e98ca4c40bc42f566281fcb66",
            "f79e80df9eb44ea580588530104c973d",
            "5059677517634d9e96510e1aa3e5b4ed",
            "eea5619602ac4bb5b68f6eadc22e707a",
            "600cf47af5324c7f84d3bb4a0343a78d",
            "577b6acfd4594c0e97f093b08f76ae8c",
            "abee0c269e51483e919a4f3d072544f6",
            "38e12ddb6d744172806bad386ddcb71f",
            "00ba81e1f8044b4e8b822bb10e9e4f16",
            "af3bc746bee146619153d442337a9e9e"
          ]
        },
        "id": "C5YitGvH-iu4",
        "outputId": "1ab3f4f0-c125-4248-8f8e-ec9ca3cede06"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b56cb82a0c8c4d0ab80cc181068e567f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Below is an instruction that describes a task, paired with an input that provides further context.\\nWrite a response that appropriately completes the request.\\nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n\\n### Instruction:\\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning.\\nPlease answer the following medical question.\\n\\n### Question:\\n根据描述，一个1岁的孩子在夏季头皮出现多处小结节，长期不愈合，且现在疮大如梅，溃破流脓，口不收敛，头皮下有空洞，患处皮肤增厚。这种病症在中医中诊断为什么病？\\n\\n### Response:\\n<think>\\n这个小孩子在夏天头皮上长了些小结节，一直都没好，后来变成了脓包，流了好多脓。想想夏天那么热，可能和湿热有关。才一岁的小孩，免疫力本来就不强，夏天的湿热没准就侵袭了身体。\\n\\n用中医的角度来看，出现小结节、再加上长期不愈合，这些症状让我想到了头疮。小孩子最容易得这些皮肤病，主要因为湿热在体表郁结。\\n\\n但再看看，头皮下还有空洞，这可能不止是简单的头疮。看起来病情挺严重的，也许是脓肿没治好。这样的情况中医中有时候叫做禿疮或者湿疮，也可能是另一种情况。\\n\\n等一下，头皮上的空洞和皮肤增厚更像是疾病已经深入到头皮下，这是不是说明有可能是流注或瘰疬？这些名字常描述头部或颈部的严重感染，特别是有化脓不愈合，又形成通道或空洞的情况。\\n\\n仔细想想，我怎么感觉这些症状更贴近瘰疬的表现？尤其考虑到孩子的年纪和夏天发生的季节性因素，湿热可能是主因，但可能也有火毒或者痰湿造成的滞留。\\n\\n回到基本的症状描述上看，这种长期不愈合又复杂的状况，如果结合中医更偏重的病名，是不是有可能是涉及更深层次的感染？\\n\\n再考虑一下，这应该不是单纯的瘰疬，得仔细分析头皮增厚并出现空洞这样的严重症状。中医里头，这样的表现可能更符合‘蚀疮’或‘头疽’。这些病名通常描述头部严重感染后的溃烂和组织坏死。\\n\\n看看季节和孩子的体质，夏天又湿又热，外邪很容易侵入头部，对孩子这么弱的免疫系统简直就是挑战。头疽这个病名听起来真是切合，因为它描述的感染严重，溃烂到出现空洞。\\n\\n不过，仔细琢磨后发现，还有个病名似乎更为合适，叫做‘蝼蛄疖’，这病在中医里专指像这种严重感染并伴有深部空洞的情况。它也涵盖了化脓和皮肤增厚这些症状。\\n\\n哦，该不会是夏季湿热，导致湿毒入侵，孩子的体质不能御，其病情发展成这样的感染？综合分析后我觉得‘蝼蛄疖’这个病名真是相当符合。\\n</think>\\n从中医的角度来看，你所描述的症状符合“蝼蛄疖”的病症。这种病症通常发生在头皮，表现为多处结节，溃破流脓，形成空洞，患处皮肤增厚且长期不愈合。湿热较重的夏季更容易导致这种病症的发展，特别是在免疫力较弱的儿童身上。建议结合中医的清热解毒、祛湿消肿的治疗方法进行处理，并配合专业的医疗建议进行详细诊断和治疗。<｜end▁of▁sentence｜>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "訓練模型\n",
        "現在讓我們使用 Huggingface TRL 的 `SFTTrainer`。\n",
        "\n",
        "我們使用peft使用變量，peft是參數高效的微調,接著用SFTTrainer創建訓練器，同時也希望train loss值越低越好。接著一樣的問題進行問答，來查看跟數據集中的答案是否接近與滿足需求，反覆調參。\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OaMfxfP5_Ez6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ],
      "metadata": {
        "id": "xQ0hTObX_GEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60,\n",
        "        # num_train_epochs = 1, # For longer training runs!\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "DHct6ZBZ_KKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bfyFk-p1_KtQ",
        "outputId": "2e00e271-f44c-4595-d42a-c3876460d7c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 500 | Num Epochs = 1 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 08:13, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.275200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.349100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.296400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.167300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.077000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.044300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.155000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.924400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.985100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.879300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.762600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.613400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.678300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.685100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.630100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.563500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.705400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.712400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.544600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.606900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.604300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.585200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.564600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.594800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.668600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.628200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.641500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.473600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.613700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.745200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.649400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.590200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.551000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.575900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.567700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.583200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.711800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.438100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.600600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.497000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.624500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.441300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.609100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.403900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.696700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.576200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.630700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.494500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.484600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.582200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.436000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.532800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.461800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.692700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.634100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.486400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.509400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.558700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.487200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.592500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 微調後的推理\n",
        "\n",
        "我們再用同樣的問題來推理，看看有什麼不同。"
      ],
      "metadata": {
        "id": "GCQjbz9c_Urb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emIZs4Cp_KuT",
        "outputId": "bb9692c0-3615-4a2d-88e6-3c087e992abb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "一个患有急性阑尾炎的病人已经发病5天，腹痛稍有减轻但仍然发热，在体检时发现右下腹有压痛的包块，此时应如何处理？\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\n",
        "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids=inputs.input_ids,\n",
        "    attention_mask=inputs.attention_mask,\n",
        "    max_new_tokens=1200,\n",
        "    use_cache=True,\n",
        ")\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "print(response[0].split(\"### Response:\")[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9AxSAtm_hNC",
        "outputId": "ed5b5326-385e-4cd4-a15a-b449568dc4a0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<think>\n",
            "这个病人已经有五天的急性阑尾炎了，虽然他的腹痛稍微好了一点，但他还是发烧的。听说在右下腹部有个包块，而且有压痛。嗯，这个包块听起来像是阑尾炎的典型表现。既然他已经有五天了，应该已经到达急性阶段了。\n",
            "\n",
            "我想到，急性阑尾炎通常是需要抗生素来治疗的。因为可能有感染，抗生素可以帮助控制细菌感染。所以，首先要考虑给他开个抗生素的药物来处理。\n",
            "\n",
            "不过，还要考虑到他的包块和压痛，这可能意味着他已经有了一个坏死的阑尾，或者可能有阻塞的情况。这种情况下，可能需要进行手术来处理。\n",
            "\n",
            "但我也要考虑到他的状况可能不太稳定。因为他已经发烧了五天，可能已经有感染的风险增加，手术可能会增加感染的风险。\n",
            "\n",
            "嗯，综合考虑，我觉得在这段时间内，最好的办法是先用抗生素来控制感染。这样可以降低感染风险，然后在病情稳定之后再考虑手术。\n",
            "\n",
            "所以，首先给他开抗生素，控制感染，然后再观察病情的变化，决定是否需要手术。\n",
            "</think>\n",
            "对于一个患有急性阑尾炎的病人，已经发病5天，腹痛减轻但仍然发热，且在右下腹部发现压痛的包块，建议的处理步骤如下：\n",
            "\n",
            "1. **抗生素治疗**：首先，开具抗生素以控制感染。通常选择针对细菌感染的抗生素，如青霉素、头孢素或第三代头孢菌素等，以控制感染。\n",
            "\n",
            "2. **监测病情**：观察病人的病情变化，包括腹痛的程度、发热情况、包块的变化以及是否有新的症状出现。这些信息有助于评估病情的稳定性和进一步的处理策略。\n",
            "\n",
            "3. **评估是否需要手术**：如果在抗生素治疗的同时，病人的包块大小不减小或有明显的增大，或者出现严重的腹痛、发热、恶寒、呕吐等症状，可能需要进一步评估是否需要手术。\n",
            "\n",
            "4. **手术评估**：如果在抗生素治疗下病情不改善，且包块增大或有阻塞，建议在病情稳定后进行阑尾切除术，以排除阑尾炎。\n",
            "\n",
            "5. **术后护理**：如果决定进行手术，术后需要密切观察，控制感染风险，并根据术后病情进行适当的治疗。\n",
            "\n",
            "总之，建议先进行抗生素治疗以控制感染，随后根据病情的变化决定是否进行手术。<｜end▁of▁sentence｜>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 上傳模型至 HuggingFace\n",
        "\n",
        "現在，讓我們儲存微調後的型號並將其上傳到 HuggingFace。"
      ],
      "metadata": {
        "id": "P0u1Od8QCHKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bmAndUi3CLka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 將微調後的模型儲存為GGUF格式\n",
        "\n",
        "將對應的“if”設為“True”，選擇我們喜歡的llama.cpp的GGUF格式。\n",
        "\n",
        "HUGGINGFACE_TOKEN請輸入你在HUGGINGFACE的TOKEN。"
      ],
      "metadata": {
        "id": "gdp-SsnhCLlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "HUGGINGFACE_TOKEN = userdata.get('HUGGINGFACE_TOKEN')"
      ],
      "metadata": {
        "id": "row-F1tDCMrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to 8bit Q8_0\n",
        "if True: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model_f16\", tokenizer, quantization_method = \"f16\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")"
      ],
      "metadata": {
        "id": "F54_5Ox8CUe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 將模型推送到 HuggingFace"
      ],
      "metadata": {
        "id": "PBLkk8KLCbGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "如果您還沒有這樣做，請為您的模型建立一個模型類型儲存庫。"
      ],
      "metadata": {
        "id": "E4KT-Sb4CfCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import create_repo\n",
        "create_repo(\"joyce914/medical-model\", token=HUGGINGFACE_TOKEN, exist_ok=True)"
      ],
      "metadata": {
        "id": "aEzwxF2BCUf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub_gguf(\"joyce914/medical-model\", tokenizer, token = HUGGINGFACE_TOKEN)"
      ],
      "metadata": {
        "id": "KyxG45mYCo4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ollama 運行 HuggingFace 模型\n",
        "\n",
        "```bash\n",
        "ollama run hf.co/{username}/{repository}:{quantization}\n",
        "```"
      ],
      "metadata": {
        "id": "-vCfHFw5DAiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ollama inference\n",
        "\n",
        "```bash\n",
        "curl http://localhost:11434/api/chat -d '{ \\\n",
        "  \"model\": \"\", \\\n",
        "  \"messages\": [ \\\n",
        "    { \"role\": \"user\", \"content\": \"一个患有急性阑尾炎的病人已经发病5天，腹痛稍有减轻但仍然发热，在体检时发现右下腹有压痛的包块，此时应如何处理？\" } \\\n",
        "  }'\n",
        "```"
      ],
      "metadata": {
        "id": "27bsylHlDNvh"
      }
    }
  ]
}