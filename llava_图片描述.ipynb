{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db8473a9c1474af98f0af43ddf56c787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8df0f16756604a06b6ca27c636a4d91f",
              "IPY_MODEL_c8a3d528700047b6a90fc3cc3b68b421",
              "IPY_MODEL_a197739605af409badc9b9d638da0619"
            ],
            "layout": "IPY_MODEL_932e0dce220849778f20939991cd9493"
          }
        },
        "8df0f16756604a06b6ca27c636a4d91f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d497361f2ae4a76889be15ae4d1cbf2",
            "placeholder": "​",
            "style": "IPY_MODEL_a6b7ffe72a814f62bfe3bdeaab134273",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c8a3d528700047b6a90fc3cc3b68b421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9716562ab8f4cc6850c1ec8bd0647d7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2d60f4ebf5a416ebb33a0b062496b3b",
            "value": 2
          }
        },
        "a197739605af409badc9b9d638da0619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6b7d694847b4eb6b4392a5a057ab04b",
            "placeholder": "​",
            "style": "IPY_MODEL_f6e018c009164dc192a0bcc406816c8d",
            "value": " 2/2 [00:04&lt;00:00,  2.18s/it]"
          }
        },
        "932e0dce220849778f20939991cd9493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d497361f2ae4a76889be15ae4d1cbf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6b7ffe72a814f62bfe3bdeaab134273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9716562ab8f4cc6850c1ec8bd0647d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2d60f4ebf5a416ebb33a0b062496b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6b7d694847b4eb6b4392a5a057ab04b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6e018c009164dc192a0bcc406816c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 环境介绍\n",
        "本示例运行在colap ，使用A100运行\n",
        "\n",
        "# 本示例概要\n",
        "本示例主要是带大家安装llava ,并透过llava实现进行图片解读\n",
        "\n"
      ],
      "metadata": {
        "id": "IE5eHiguKMIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1️⃣ 檢查 GPU 是否可用\n",
        "在 Colab 內執行以下命令，確保啟用了 GPU（建議 A100 或更強的顯卡）："
      ],
      "metadata": {
        "id": "jR4JPKWqLMEq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8IICzU_aRym"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2️⃣ 安裝所需的依賴庫\n",
        "執行以下命令來安裝 LLaVA 需要的套件："
      ],
      "metadata": {
        "id": "rgUB-lLvLX62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install transformers accelerate\n",
        "!pip install bitsandbytes\n",
        "!pip install git+https://github.com/huggingface/peft.git\n",
        "!pip install git+https://github.com/huggingface/diffusers.git\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install git+https://github.com/huggingface/huggingface_hub.git\n"
      ],
      "metadata": {
        "id": "quscn9Dcaeit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3️⃣ 下載 LLaVA 專案 并使用safetensors这种高效的权重格式来减少记忆体占用,这边要注意要先建立LLaVA档案夹\n",
        "这边要注意的是我clone llava模型地址会变动，可能会因为不同版本导致安装过程有变化哦！"
      ],
      "metadata": {
        "id": "eGzxUYCaLbdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/haotian-liu/LLaVA.git\n",
        "%cd LLaVA\n",
        "!pip install -e .\n",
        "!pip install safetensors"
      ],
      "metadata": {
        "id": "meo3Jv1pa4Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "因为避免OOM，我这里手動設定 PyTorch CUDA 記憶體管理512来减少GPU记忆体碎片化提高可用记忆体"
      ],
      "metadata": {
        "id": "kXFC-XhQL_AP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n"
      ],
      "metadata": {
        "id": "WpM34wKSickR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "因为安裝 bitsandbytes（8-bit 量化庫）（大幅降低顯存占用），在环境的设定上指定统一格式"
      ],
      "metadata": {
        "id": "2wpZ7Q7vMh-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "!pip install bitsandbytes\n"
      ],
      "metadata": {
        "id": "vIyROUM_jQaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4️⃣ 下載 LLaVA 預訓練模型\n",
        "这边的优化项目我一一说明\n",
        "\n",
        "🔹 BitsAndBytesConfig 的作用\n",
        "\n",
        "1.   load_in_8bit=True（啟用 8-bit 量化，降低 VRAM 需求）\n",
        "這行表示：將 LLaVA 模型的權重轉換為 8-bit 精度（預設情況下是 16-bit fp16 或 32-bit fp32）。這樣可以大幅減少模型的 GPU 記憶體占用（約降低 50%），但仍保留一定的計算精度。🔹 效益：降低 VRAM 需求，使模型能夠在 Colab A100上運行。\n",
        "比 4-bit 更準確，但比 16-bit 省記憶體。\n",
        "2.   llm_int8_enable_fp32_cpu_offload=True（將 FP32 權重卸載到 CPU，釋放 VRAM）\n",
        "這行表示：部分需要高精度的 FP32 權重將被卸載到 CPU，減少 GPU 記憶體使用。\n",
        "在 8-bit 量化中，某些特定的層仍然需要 fp32 來保持模型的運算穩定性，所以這裡讓它們移到 CPU 來節省 GPU 記憶體。🔹 效益：避免「CUDA Out of Memory (OOM)」錯誤。\n",
        "減少記憶體碎片化，提高運行效率。\n",
        "3.   load_in_8bit_fp32_cpu_offload=True（進一步將 FP32 權重完全移到 CPU）\n",
        "這行表示：完全將 FP32 權重存放在 CPU，而不是 GPU。這可以進一步降低 GPU 記憶體需求，但可能會降低推理速度（因為需要 CPU-GPU 數據傳輸）。🔹 效益：減少 GPU 記憶體占用，確保 LLaVA 可以在低記憶體環境下運行。\n",
        "4.   bnb_4bit_compute_dtype=torch.bfloat16（計算時使用 bfloat16 以提升精度）\n",
        "這行表示：設置 4-bit 計算的數據類型為 bfloat16（BF16）。bfloat16 是一種較新的數據格式，能夠保持 fp32 精度的範圍，但只占一半記憶體。🔹 效益：提高數值計算的穩定性，避免過度量化導致的精度損失。相比 fp16，bfloat16 更穩定且更適合較新的 GPU（如 A100、V100）。\n",
        "5.   bnb_4bit_quant_type=\"nf4\"（使用 NF4 量化，提高 4-bit 模型的精度）\n",
        "這行表示：使用 NF4（Normal Float 4）來做 4-bit 量化。\n",
        "NF4 是 bitsandbytes 特有的一種 4-bit 量化格式，它比傳統的 4-bit 量化方法更準確。\n",
        "🔹 效益：能夠在 4-bit 量化的情況下保留更高的精度。避免過度量化造成模型性能下降。\n",
        "\n",
        "🔹 load_pretrained_model 的作用\n",
        "\n",
        "\n",
        "1.   device_map=\"auto\"（自動選擇 CPU 或 GPU 運行）讓 transformers 自動分配模型到 GPU 或 CPU，確保不會超過 GPU 記憶體。若 VRAM 不足，會自動將部分層卸載到 CPU。\n",
        "🔹 效益：防止 CUDA 記憶體不足（OOM）錯誤。根據硬體資源自動最佳化。\n",
        "2.   offload_folder=\"./content/offload_weights\"（存放卸載的權重）當 VRAM 不夠時，某些層會被卸載到磁碟，這裡指定它們存放的位置。🔹 效益：允許 LLaVA 在低記憶體環境運行（Colab T4、V100）。避免記憶體不足導致崩潰。\n",
        "3.   quantization_config=quantization_config（啟用 8-bit 量化配置）告訴 load_pretrained_model 使用 剛剛定義的 8-bit 量化配置。🔹 效益：\n",
        "讓 LLaVA 以更少的 GPU 記憶體運行。確保 8-bit 量化和 CPU Offload 設置生效\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FpqA6BCaNy9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from llava.model.builder import load_pretrained_model\n",
        "from llava.mm_utils import get_model_name_from_path\n",
        "from transformers import BitsAndBytesConfig, AutoTokenizer\n",
        "\n",
        "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
        "\n",
        "# Try loading in 8-bit with CPU offload and fp32 cpu offload\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,  # Load in 8-bit\n",
        "    llm_int8_enable_fp32_cpu_offload=True,  # Enable CPU offload for fp32 weights\n",
        "    #load_in_8bit_fp32_cpu_offload=True,  # Offload fp32 weights to CPU\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,  # Set compute dtype for 4-bit quantization (if needed)\n",
        "    bnb_4bit_quant_type=\"nf4\"  # Set quantization type for 4-bit quantization (if needed)\n",
        ")\n",
        "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
        "    model_path=model_path,\n",
        "    model_base=None,\n",
        "    model_name=get_model_name_from_path(model_path),\n",
        "    device_map=\"auto\",                # Use automatic device mapping\n",
        "    offload_folder=\"./content/offload_weights\", # Set the offload folder\n",
        "    quantization_config=quantization_config  # Pass the quantization config\n",
        ")"
      ],
      "metadata": {
        "id": "nAWtn51QeYOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5️⃣ 測試 LLaVA\n",
        "上传一张图片请llava根据我的prompt指令进行描述"
      ],
      "metadata": {
        "id": "ww8fC2YBODdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llava.eval.run_llava import eval_model\n",
        "\n",
        "prompt = \"這張圖片中有什麼值得注意的地方？\"\n",
        "image_file = \"https://llava-vl.github.io/static/images/view.jpg\"\n",
        "\n",
        "args = type('Args', (), {\n",
        "    \"model_path\": model_path,\n",
        "    \"model_base\": None,\n",
        "    \"model_name\": get_model_name_from_path(model_path),\n",
        "    \"query\": prompt,\n",
        "    \"conv_mode\": None,\n",
        "    \"image_file\": image_file,\n",
        "    \"sep\": \",\",\n",
        "    \"temperature\": 0,\n",
        "    \"top_p\": None,\n",
        "    \"num_beams\": 1,\n",
        "    \"max_new_tokens\": 512\n",
        "})()\n",
        "\n",
        "eval_model(args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "db8473a9c1474af98f0af43ddf56c787",
            "8df0f16756604a06b6ca27c636a4d91f",
            "c8a3d528700047b6a90fc3cc3b68b421",
            "a197739605af409badc9b9d638da0619",
            "932e0dce220849778f20939991cd9493",
            "3d497361f2ae4a76889be15ae4d1cbf2",
            "a6b7ffe72a814f62bfe3bdeaab134273",
            "a9716562ab8f4cc6850c1ec8bd0647d7",
            "c2d60f4ebf5a416ebb33a0b062496b3b",
            "f6b7d694847b4eb6b4392a5a057ab04b",
            "f6e018c009164dc192a0bcc406816c8d"
          ]
        },
        "id": "2Cv4XstNcsuQ",
        "outputId": "da31a764-e5dd-4b9e-cb65-944244300f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db8473a9c1474af98f0af43ddf56c787"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `None` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "這張圖片中有一個漂亮的木板步道，它穿過一個湖，並且有一個山脈在背景中。這個步道的設計非常吸引人，因為它從湖面上延伸到山脈上，讓人感受到自然的美麗和寧靜。此外，這個步道的位置非常優越，因為它可以讓人欣賞到湖面和山脈的美景，並且可以提供一個漫步或遠足的好地方。\n"
          ]
        }
      ]
    }
  ]
}